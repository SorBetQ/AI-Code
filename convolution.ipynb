{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61969c98",
   "metadata": {},
   "source": [
    "# conv2d\n",
    "\n",
    "[from](https://blog.csdn.net/panghuzhenbang/article/details/129713598)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "def conv2d(inputs, in_channels, out_channels, kernel_size, stride = 1, padding = 0, weights = None, bias = None):\n",
    "    if weights == None:\n",
    "        weights = torch.randn([out_channels, in_channels, kernel_size[0], kernel_size[1]])\n",
    "    if bias is None:\n",
    "        bias = torch.zeros(out_channels)\n",
    "\n",
    "    def fixed_padding(inputs, kernel_size):\n",
    "        pad_total = kernel_size - 1\n",
    "        pad_beg = pad_total / 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        padded_inputs = F.pad(inputs, [pad_beg, pad_end, pad_beg, pad_end], mode= 'constant', value = 0)\n",
    "        return padded_inputs\n",
    "        \n",
    "    if padding:\n",
    "        padded_inputs = F.pad(inputs, [padding, padding, padding, padding], mode='constant', value=0)\n",
    "    else:\n",
    "        padded_inputs = fixed_padding(inputs, kernel_size)\n",
    "\n",
    "    n, c, w, h = padded_inputs.shape\n",
    "    outputs = []\n",
    "\n",
    "    for i, imgs in enumerate(padded_inputs):\n",
    "        one_batch_out = []\n",
    "        for j in range(out_channels):\n",
    "            feature_map = []\n",
    "            row = 0\n",
    "            \n",
    "            while row + kernel_size[0] <= h:\n",
    "                row_feature_map = []\n",
    "                col = 0\n",
    "\n",
    "                while col + kernel_size[1] <= w:\n",
    "                    point = [0 for ch in range(c)]\n",
    "                    for ch in range(c):\n",
    "                        for y in range(kernel_size[0]):\n",
    "                            for x in range(kernel_size[1]):\n",
    "                                point[ch] += imgs[ch][row+y][col+x] * weights[j][ch][y][x]\n",
    "                    point = sum(point) + bias[j]\n",
    "                    row_feature_map.append(point)\n",
    "                    col += stride[1] if isinstance(stride, (list, tuple)) else stride\n",
    "                feature_map.append(row_feature_map)\n",
    "                row += stride[0] if isinstance(stride, (list, tuple)) else stride\n",
    "            one_batch_out.append(feature_map)\n",
    "        outputs.append(one_batch_out)\n",
    "    \n",
    "    return torch.tensor(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027a3f5",
   "metadata": {},
   "source": [
    "# pool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831494b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pooling(inputs, pool_size, stride, mode = 'max'):\n",
    "    c, w, h = inputs.shape\n",
    "    k = pool_size\n",
    "    outputs = np.zeros((c, (w - k) / stride + 1, (h - k) / stride + 1))\n",
    "\n",
    "    if mode == 'max':\n",
    "        for i in range(0, w - k + 1, stride):\n",
    "            for j in range(0, h - k + 1, stride):\n",
    "                outputs[:, i / stride, j / stride] = np.max(inputs[:, i:i+k, j:j+k], axis = (1,2))\n",
    "        return outputs\n",
    "    elif mode == 'avg':\n",
    "        for i in range(0, w - k +1, stride):\n",
    "            for j in range(0, h - k + 1, stride):\n",
    "                outputs[:, i / stride, j / stride] = np.mean(inputs[:, i:i+k. j:j+k], axis = (1,2))\n",
    "        return outputs\n",
    "    else:\n",
    "        raise ValueError('not support this mode, choose \"max\" or \"avg\" ')\n",
    "\n",
    "def test():\n",
    "    pool_size = 2\n",
    "    stride = 2\n",
    "    mode = 'max'\n",
    "    inputs = np.arrange(1, 76).reshape((3, 5, 5))\n",
    "    outputs = pooling(inputs, pool_size, stride, mode)\n",
    "    print(\"outputs:{}\".format(outputs.shape), '\\n', outputs)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac146e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 25, kernel_size=3),\n",
    "            nn.BatchNorm2d(25),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(25, 50, kernel_size=3),\n",
    "            nn.BatchNorm2d(50),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(50 * 5 * 5, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72815301",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvRNN(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        pad_x = int(dilation * (kernel_size - 1) / 2)\n",
    "        self.conv_x = nn.Conv2d(in_dim, out_dim, kernel_size, padding=pad_x, dilation=dilation)\n",
    "\n",
    "        pad_h = int((kernel_size - 1) / 2)\n",
    "        self.conv_h = nn.Conv2d(out_dim, out_dim, kernel_size, padding=pad_h)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x, h = None):\n",
    "        if h is None:\n",
    "            h = F.tanh(self.conv_x(x))\n",
    "        else:\n",
    "            h = F.tanh(self.conv_x(x) + self.conv_h(h))\n",
    "        \n",
    "        h = self.relu(h)\n",
    "        return h, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde918da",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        pad_x = int(dilation * (kernel_size - 1) / 2)\n",
    "        self.conv_xf = nn.Conv2d(in_dim, out_dim, kernel_size, padding=pad_x, dilation=dilation)\n",
    "        self.conv_xi = nn.Conv2d(in_dim, out_dim, kernel_size, padding=pad_x, dilation=dilation)\n",
    "        self.conv_xo = nn.Conv2d(in_dim, out_dim, kernel_size, padding=pad_x, dilation=dilation)\n",
    "        self.conv_xj = nn.Conv2d(in_dim, out_dim, kernel_size, padding=pad_x, dilation=dilation)\n",
    "\n",
    "        pad_h = int((kernel_size - 1) / 2)\n",
    "        self.conv_hf = nn.Conv2d(out_dim, out_dim, kernel_size=kernel_size, padding= pad_h)\n",
    "        self.conv_hi = nn.Conv2d(out_dim, out_dim, kernel_size=kernel_size, padding= pad_h)\n",
    "        self.conv_ho = nn.Conv2d(out_dim, out_dim, kernel_size=kernel_size, padding= pad_h)\n",
    "        self.conv_hj = nn.Conv2d(out_dim, out_dim, kernel_size=kernel_size, padding= pad_h)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "    \n",
    "    def forward(self, x, pair = None):\n",
    "        if pair is None:\n",
    "            i = F.sigmoid(self.conv_xi(x))\n",
    "            j = F.sigmoid(self.conv_xj(x))\n",
    "            c = i * j\n",
    "            o = F.sigmoid(self.conv_xo(x))\n",
    "            h = o * c\n",
    "        else:\n",
    "            h, c = pair\n",
    "            f = F.sigmoid(self.conv_xf(x) + self.conv_hf(h))\n",
    "            i = F.sigmoid(self.conv_xi(x) + self.conv_hi(h))\n",
    "            j = F.sigmoid(self.conv_xj(x) + self.conv_hj(h))\n",
    "            c = f * c + i * j\n",
    "            o = F.sigmoid(self.conv_xo(x) + self.conv_ho(h))\n",
    "            h = o * F.tanh(c)\n",
    "        \n",
    "        h = self.relu(h)\n",
    "        return h, [h, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc8d268",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvGRU(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        pad_x  = int(dilation * (kernel_size - 1) / 2)\n",
    "        self.conv_xz = nn.Conv2d(in_dim, out_dim, kernel_size, padding=pad_x, dilation=dilation)\n",
    "        self.conv_xr = nn.Conv2d(in_dim, out_dim, kernel_size, padding=pad_x, dilation=dilation)\n",
    "        self.conv_xn = nn.Conv2d(in_dim, out_dim, kernel_size, padding=pad_x, dilation=dilation)\n",
    "\n",
    "        pad_h = int((kernel_size - 1) / 2)\n",
    "        self.conv_hz = nn.Conv2d(out_dim, out_dim, kernel_size, padding=pad_h)\n",
    "        self.conv_hr = nn.Conv2d(out_dim, out_dim, kernel_size, padding=pad_h)\n",
    "        self.conv_hn = nn.Conv2d(out_dim, out_dim, kernel_size, padding=pad_h)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x, h = None):\n",
    "        if h is None:\n",
    "            z = F.sigmoid(self.conv_xz(x))\n",
    "            f = F.sigmoid(self.conv_xn(x))\n",
    "            h = z * f\n",
    "        else:\n",
    "            z = F.sigmoid(self.conv_xnz(x) + self.conv_hz(h))\n",
    "            r = F.sigmoid(self.conv_xr(x) + self.conv_hr(h))\n",
    "            n = F.tanh(self.conv_xn(x) + self.conv_hn(r * h))\n",
    "            h = (1 - z) * h + z * n\n",
    "\n",
    "        h = self.relu(h)\n",
    "        return h, h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
